Preliminary Data Collection (1)
===============================
This report covers the process of collecting data across two days, the 16th and 17th of February (Sat-Sun) 2013.

The method followed was that detailed in the [preliminary procedures](PreliminaryProcedures) document.

Methodological Findings
-----------------------
The process of recording was remarkably easy, though it did demand a fair amount of effort to keep the notebook with me, and at time this was not possible.


### Audio
I used constant audio recording for all verbal communication, and noted down anything read or any activities which involved complex interaction and would have covered me reading certain things (such as filling the car with petrol).  

This yielded a wealth of difficult-to-process data in the form of verbatim recordings, with no index.  Extracting meaningful data from this will prove extremely hard, as existing voice activity detection systems seem incapable of achieving a usable reliability.  Some alternatives would be:

 1. Use the dictaphone to record notes spoken to myself, including times, persons present, etc. (but otherwise record nothing)
 2. Turn the dictaphone off between conversations (might be awkward for short interactions, does not give information on time)
 3. Key the recording by using the index mark button, an audible (and visible on spectrum) 'clicker', or an in-line custom buzzer unit
 4. Develop methods for manual annotation guided by VAD

Of these, I believe 3 is the most practical.


### Digital Documents
Throughout the experiment I used a remarkable seven web browsers, across my phone, tablet, and desktop machine.  It became essentially impractical to export the histories, which are not typically 'exportable' from most browsers.

In addition to this, I listened to quite a few radio programmes on the iplayer, something that will require care to report properly.  Though the pages appear in the web history, it is unclear which were listened to in full and which were unplayed or skipped.  The same is true for all text, and it turns out that I read a very very small proportion of any web page text (this is hinted at in various web design manuals too).

In order to record histories better, a proxy is needed to create coherent, centralised logs of web usage.


### Large Bodies of Text (physical)
Things such as books and papers were remarkably easy to note down, since I'd often read a whole page or paragraph, and the titles and physical copies themselves are easy to recreate (requiring only a quick mnemonic in my notebook).


### Brands, Ephemera, Semi-conscious Acknowledgement
Much of what was read on a daily basis was the branding of products, road signs, cooking instructions etc.  These are often "stealthy", and it can be hard to notice that one's reading anything at all.  In order to alias these in a useful manner, I will be keeping a diary of activities in order to resolve any missing parts (in addition to continued recording).

For these events, it may be worth noting some activity-specific properties, such as which shops I visited (and a list of products), if I spoke to cashiers, bought lunch, etc.


### Difficult Contexts
I can't note things in my notebook when driving.  Recording (or even counting) things like road signs, billboards and fuel stops requires video recording, something that may be applied for short (reviewable) periods such as this.

Over the weekend I went climbing, and had to remove my recording equipment lest it be damaged.  In reality, however, it could probably simply be re-placed and should still be practical.


### Music
I listen to a fair amount of music, via services such as spotify, the radio, and live.  Audio recording is one obvious way to capture this, but resolving the names of songs then becomes difficult.  A solution to this issue will likely centre around a number of techniques:

 1. Songs played on computers may be synced to last.fm, and the data later downloaded (or recorded nightly in the diary)
 2. Songs played on my mp3 player may be "prev"ed at the end of a day, though this does not cover ones I skipped.  When in the car this could be captured on the video for review.
 3. Songs played on the radio must be recorded using verbatim recordings.  Radio start/end points should be noted in the notebook for cross-referencing.


### Polyphony/Multi-media
The degree to which I am listening to a radio program whilst also, say, reading a book or writing in my notebook, is debatable.  There's no reason all may not be recorded, however, some annotation scheme should be found for the final collation of data that is capable of expressing this.


### Production of content
It's very unclear how often I read content I am creating, or how often I refer to something when transcribing it.  The only way this could be truly determined would be using a headset to identify gaze, but it may be estimated informally whilst on the task (or shortly after).  I propose adding this to the diary information.


### Summary
In addition to the points recommended for each section above, a diary should be kept, with an entry every night discussing:

 1. All linguistically-relevant events, recanted in order, with subjective notes that may influence data collation
 2. Listings of music and other difficult-to-sample things that must be retrieved from devices/the world (shopping lists, etc)
 3. Subjective descriptions of how often some content was read/referred to
 4. Notes on how much of a certain type of resource I 'tend to' read (i.e. story and 2-3 comments on news articles, top comment on imgur)



Insights into Data
------------------

### Variance
I consume lots of very small amounts of text from written sources daily, and these sources vary wildly (far far more than most corpora would imply).  In one day, for example, I read articles on music theory, a guidebook for climbers, food cooking instructions, brand names on many items of clothing and food, instructions for how to do various things, GPS instructions and maps, and road signs.  

This implies that a "good" representative sample of language usage will necessarily contain a lot of what would normally be considered noise.  The extent to which this only-vaguely-read stuff actually influences me should not, in my opinion, be underestimated: many phrases and memes come from advertising and shared experience.

This also implies that one would have to sample for a fairly long time to see the signal over the noise.  That is, a corpus will have to grow rather large before it includes any whole books, let alone a cross-section of genres.  This is an argument for using hybrid methodologies involving questionnaires and such.


### Partial Consumption
I seldom read all of anything.  Especially on the web, I will check out only one or two comments on an image, or read only until I have discovered the fact I am looking for.  This should definitely be noted in some way, as should the size of the sample I read (it is most definitely below the 2000 word mark on average).

This contributes to the point about variance too.


### "Stealth" Text
I find myself subconsciously absorbing text without really actively reading it.  This covers things like TV subtitles and quick notes for myself, as well as things like advertising, calendars, branding, etc.  Learning to recognise the act of reading stuff will be a major challenge in recording it.

### Proportions of Spoken Language
The vast proportion of all words used were spoken.  Nevertheless, I would suggest that the vast majority of *content* was read from digital sources.  The number of individual language conveyance events used was probably around 50-50, when counting small-scale signage and such.

It seems likely that, day-to-day, these proportions will be highly variable, forming another argument for extended sampling in order to get a good indication of corpus proportions.

