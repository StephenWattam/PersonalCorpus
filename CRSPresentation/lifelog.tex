
\documentclass[xcolor=x11names,compress]{beamer}


\usetheme[nocurve]{SmartSerif}

\usepackage{graphicx}
\DeclareGraphicsExtensions{.pdf,.png,.jpg}
\graphicspath{{./images/}}
\usepackage{color}

\newcommand{\noimage}{\includegraphics{placeholder}}


% ---------------------------------------------------------------------------------------
% Thanks to http://www.guidodiepen.nl/2009/07/creating-latex-beamer-handouts-with-notes/
 % \usepackage{handoutWithNotes}
 % \pgfpagesuselayout{4 on 1 with notes}[a4paper,border shrink=5mm]
 % \pgfpagesuselayout{2 on 1 with notes landscape}[a4paper,border shrink=5mm]
% ---------------------------------------------------------------------------------------

\setcounter{tocdepth}{2}

\title{Using Life-Logging to Re-Imagine Representativeness in Corpus Design}
\author{Stephen Wattam}
\institute[2013]{Lancaster University}
\date{\tiny \today}

\begin{document}

\maketitle

\frame{\frametitle{Contents}
    \tableofcontents
}




% -----------------------------------------------------------------------------------------
% \frame{\frametitle{Balance/Representativeness}
% 
%         % Representativeness is, simply:
%         Maximising the extent to which a sample resembles the population
% 
%         % For a given question 
%         % For a given population (needs defining)
% 
% 
%         \begin{itemize}
%             \item \textbf{Balance/Proportionality}---The ability of each sample to relate to its real-world counterpart
%                 % As seen in some given dimension
%                     
%             \item \textbf{Size}---The ability to adequately represent sub-populations fully for subsampling and specific inquiry
%                 % i.e. is there enough data on a given subtype of language?
%         \end{itemize}
% 
%         Language is so complex that, to satisfy these for a given research question, we require a very large sampe size
% 
% \note{}
% }
% 

\section{Sampling Design}



\subsection{Conventional Sampling}
\frame{\frametitle{Conventional Corpus Design}
    \begin{itemize} 
        \item Views language as a persistent, static entity
    % i.e. books themselves, rather than the act of reading

\item Stratified along genre, medium, etc.
    % This differs from social science samples, who usually use variation across
    % the social population
    % 
    % There's a fair amount of disagreement on what variables are most important still
    %
    % It's not possible to sample consumption/production without having better information on these

\item Based on available indexes such as bestseller lists
    % i.e. bestseller lists, etc

\item Tightly coupled to expert opinion on text importance
    % Which lists to use, etc, is chosen by committee
    % these have direct influence on content (selecting more books, for example)

\end{itemize}

\note{
    BNC: "Texts were chosen for inclusion according to three selection features: domain (subject field), time (within certain dates) and medium (book, periodical, etc.)."
}
}


\frame{\frametitle{Difficulties}
    \begin{itemize}
        \item Many variables don't have indexes
            % (i.e. production vs consumption)
        \item Ethical or legal concerns limit some types of data
            % i.e. speech vs writing proportions
        \item Selection using `proxy variables', due to lack of auxiliary data
            % and these have interactions with other variables of interest, i.e. p[in index list] correlates with some social/linguistic property
        \item True empirical distribution of many variables is unknown
            % leading to unrepresentative choices for stratum size
            % such as time authored/read vs "was made in this year"
    \end{itemize}

    \note{}
}


\subsection{Literature}
\frame{\frametitle{Literature \& Criticism}
    \begin{itemize}
        \item Biber
        \item Varadi
        \item Leech
        \item
    \end{itemize}
\note{}
}

% NOTE: another approach here would be to send out questionnaires in order to assess
%       the social validity of corpus results, i.e. to check the indexes.

\subsection{Demographic Sampling}
\frame{\frametitle{Demographic Sampling}
    \begin{itemize}
    
        \item Views language use as a transitive event
% a language transaction, a la Leech

\item Stratified along demographic variables
% as in the BNC's demographic speech sample
% as with virtually all other social science samples

\item Expert opinion only needed to select demographics
% though sample size is still a hot topic and always will be
% population is now "all users of x language",
% the users can be determined through other surveys

\item Opportunities for census of language genres
% Constant recording can record everything, for once
% Personal corpus stuff.

\end{itemize}
    % \begin{itemize}
    %     \item 

    %     \item Selecting different variables of interest re-orients many practical issues
    %     % back to basics --- what is the aim of CL?
    %     \item I've chosen to sample language as a social, transitive, event
    %         % i.e. for a given group of people, what language do they use?
    %     \item Sample proportions of language use 'in the wild'
    %     \item With sufficient sample size, this is equivalent, however, pragmatic sampling issues differ greatly
    % \end{itemize}
\note{}
}


\frame{\frametitle{Advantages}
    \begin{itemize}
        \item Social demographics are well documented
        \item No central index is required 
            % The person is a central index
        \item Additional variables are exposed to study
            % production/consumption, time/context etc.
            % more variables, i.e. not only author/title/genre (which may still be there),
            % but also social ones and transitive ones
        \item Discovery of language types/uses possible
            % ephemera, TV, labels, billboards etc

    \end{itemize}

\note{}
}


\frame{\frametitle{New Difficulties}
    \begin{itemize}
        \item Sampling text from many people is technically demanding, expensive
            % We have to leave the office more
            % technology makes this easier nowadays
            % This is also an issue for things like the BHPS
        \item Size issues now affect `how many people'
            % difficult even for simple data
            % dependent on the variability of people's everyday usage (a la biber)
        \item Multi-modal sources require transcription 
            % but this can be helped by using the sample as auxiliary data
            % Many things don't start of so well curated
    \end{itemize}
\note{}
}




\section{Life-Logging}
\subsection*{History}
\frame{\frametitle{Life-Logging}
    \begin{itemize}
        \item Continual verbatim recording/broadcasting of life
        \item Originally for entertainment (JenniCam, Justin.tv)
        \item Heavily reliant on portable technology, connectivity

        % TODO: pics
    \end{itemize}
\note{}
}


\subsection*{Application to Corpus Design}
\frame{\frametitle{Applications}
    \begin{itemize}
        \item Memory augmentation: Steve Mann, SenseCam, Machine Listening
        \item Information retrieval: DARPA LifeLog
        \item Language acquisition: Deb Roy
        \item Corpus Building: BNC's demographic speech section
        \item Posterity/Narcissism: Dymaxion Chronofile, JenniCam
    \end{itemize}
\note{
    BNC: "Recruits who agreed to take part in the project were asked to record all of their conversations over a two to seven day period."
    BNC: "Given that we were not attempting to represent the complete range of age and social groups within each region..."
}
}



\section{Method}
\subsection*{Aims/RQs}


\frame{\frametitle{}

    \begin{center}
    \sc \Large Preliminary Study 
    \end{center}

    % TODO: slide needs some work
\note{}
}

\frame{\frametitle{Aims}
Construct a personal corpus, to determine:

    \begin{itemize}
        \item What proportions of language types I use
        \item If any types of language are missing entirely from existing corpora
            % Yes, Chomsky was correct ;-)
        \item Relative proportions of text and speech
        \item Practical methods for deployment using other subjects
        \item Time required to build a useful sample size
            %(based on variation seen, temporal cyclic stuff);
    \end{itemize}

% In addition to this, I have a number of studies planned using the data, but those can wait
\note{}
}

\frame{\frametitle{Process}
    \begin{itemize}
        \item Record all language used (produced or received), in all formats.
        \item Compile daily lists of language types used
        \item Transcribe and covert logs into a usable corpus.
            % What constitutes long enough?
    \end{itemize}
\note{}
}



\section{Data Collection}
\subsection*{Methods}
% What to record
% 'later lookup'/notes
% trade-off between seamlessness and comprehensiveness
\frame{\frametitle{Collection Strategy}
    \begin{itemize}
        \item Focus on unobtrusive, recall-based logging

        \item Daily journal of language use:
            \begin{itemize}
                \item Listings of language used
                \item Subjective descriptions of which sections were read
                \item Details of complex interactions (shopping, music)
                \item Annotation of daily continuous logs
            \end{itemize}

    \end{itemize}
\note{}
}

% Methods (one slide each?)
%  - technical
%   - squid
%   - recording (a/v)
%   - blog
%   - notebook
\frame{\frametitle{Data Sources}

Persistent sources may be retrieved easily and need not be recorded verbatim
    \begin{itemize}
        \item Books
        \item Music
        \item Audio/video, recorded
        \item Handwritten notes
    \end{itemize}

\note{}
}

\frame{\frametitle{Data Sources 2}
 
Ephemeral resources must be recorded verbatim, or are impractical to recall
    \begin{itemize}
        \item Speech
        \item Billboards; advertising; labelling
        \item Broadcast media
        \item Todo lists, personal notes
        \item Talking to myself
    \end{itemize}



\note{}
}

\frame{\frametitle{Data Sources 3}

Resources of digital origin are generally easier to capture verbatim

    \begin{itemize}
        \item Documents, presentations and other files
        \item Website contents; emails
        \item Web chat logs
        \item CLI terminal usage; keyboard input
    \end{itemize}

\note{}
}


\frame{\frametitle{Journal}
The journal is formed from a physical notebook:

% TODO picture of my notebooks
\begin{center}\includegraphics[width=3cm,height=2cm]{placeholder}\end{center}

And an online log, which contains more detail:

    \begin{itemize}
        \item Music listened to
        \item Details of complex activities I'm likely to forget
            %(items bought at shops, etc)
        \item Subjective estimates of proportions read from various sources
            %(web pages, books, etc)
    \end{itemize}
\note{}
}


\frame{\frametitle{Audio Recording}

    % TODO: pic
\begin{center}\includegraphics[width=3cm,height=2cm]{placeholder}\end{center}
    
    \begin{itemize}
        \item Allows capture of small-scale speech events
        \item Difficult to process post-hoc without index markers, but realtime annotation is harder
        \item The law prevents external use without consent
    \end{itemize}
\begin{center}\alert{Ethical issues abound!}\end{center}
\note{}
}


\frame{\frametitle{Video Recording}

    % TODO: pic
\begin{center}\includegraphics[width=3cm,height=2cm]{placeholder}\end{center}

    \begin{itemize}
        \item Very detailed multi-media recording for awkward situations
        \item Useful when driving for road signs, music, GPS instructions, etc.
        \item Difficult to annotate without 100\% time overhead
    \end{itemize}
\note{}
}

\frame{\frametitle{Technical--- Web}
\begin{center}\includegraphics[width=7cm,height=2cm]{squid}\end{center}
    \begin{itemize}
        \item SQUID Proxy logs all traffic from my devices
        \item Heavy post-processing necessary:
            \begin{itemize}
                \item Removal of AJAX, automated, unread data
                \item Filtering of tags, boilerplate
                \item Removal of unread sections of text
            \end{itemize}
        \item A bot monitors web chat when I start speaking, and only logs when I am active
    \end{itemize}
\note{}
}

\frame{\frametitle{Technical---Other Digital Resources}
\begin{center}\includegraphics[width=3cm]{wik}\end{center}

    \begin{itemize}
        \item The journal and file store are accessible via the web
        \item Any files can simply be uploaded, or
        \item A flash drive can be used for large files
    \end{itemize}
\note{}
}


\frame{\frametitle{Technical---Input}
\begin{center}\includegraphics[width=3cm,height=2cm]{placeholder}\end{center}
    \begin{itemize}
        \item Terminal-logging software can record all CLI use
        \item Keyloggers can capture all input, but often lack context information
        \item Email, web chat, other documents are all logged and timestamped anyway
    \end{itemize}
\note{}
}




\frame{\frametitle{Digitisation}

\begin{columns}[t]
    \column{.6\textwidth}

        \begin{itemize}
            \item Cameraphone for billboards and packages
            \item Thanks to tumblr, no-one cares that I'm taking a photo of some cereal packets in public
            \item Longer documents can usually be scanned
        \end{itemize}

    \column{.4\textwidth}
        \begin{center}\includegraphics[width=4cm]{food-blogger}\end{center}
\end{columns}

\note{}
}




\subsection*{Transcription}
% How to convert and transcribe data from disparate sources
% information processing, organisation, markup
\frame{\frametitle{Operationalisation}
    \begin{itemize}
        \item Only `easily lost' data is transcribed during the study (daily)
        \item Variable selection deliberately small to minimise interruptions


        \item Audio, Video are most problematic

        \item Data stored centrally for easy lookup

        % \item Digital documents require significant post-processing to remove unread content
        %     % markup, or simply bits I don't read of web pages
        %     % most terminal output is unread
        %     % I'm not *always* reading web chat
        % \item Audio needs to be annotated for genre, particpant count, etc. or transcribed
        % \item Pictures require transcription
        % \item Notebook metadata needs tabulating (and, in many cases, completing)
        % \item Web logs need downloading, post-processing
    \end{itemize}
\note{}
}


\section{Use} 
\subsection*{Use}
% Use as auxiliary data
% Resampling
% The idea of gathering more people's info
% Digital-only corpora for web scraping and rabalancing
% subject-specific corpora
\frame{\frametitle{Direct Use}
    \begin{itemize}
        \item NLP models for `custom' interaction with devices and services
            % google's personal search, sat nav
        \item Balancing of corpora to specific demographics or people
        \item Contextualisation of utterances with peer groups, etc
        \item Comparison to existing language resources
    \end{itemize}
\note{}
}

\frame{\frametitle{Methods for auxiliary data}
    \begin{itemize}
        \item Conventional corpora may be resampled to build a larger corpus
        \item Inspecting similar demographics from existing corpora indicates the differences in bias between both methods
        % TODO
    \end{itemize}
\note{}
}


\section{Findings \& Discussion}
\subsection*{Findings}
% Check prelim report
\frame{\frametitle{Findings --- Linguistic}
I read very eclectic things.
            % In one day, for example, I read articles on music theory, a guidebook for climbers, food cooking instructions, brand names on many items of clothing and food, instructions for how to do various things, GPS instructions and maps, and road signs.
            % This implies that a good representative sample will require a lot more text than first suspected
            % Low signal-noise ratio: That is, a corpus will have to grow rather large before it includes any whole books, let alone a cross-section of genres.
\note{}
}

\frame{\frametitle{Findings --- Linguistic 2}
        I rarely read \textsl{all} of \textsl{anything}
            % Correlates with design advice for the web, but I often read only one or two lines of comment
\note{}
}

\frame{\frametitle{Findings --- Linguistic 3}
        Text can sneak up on you
            % I find myself subconsciously absorbing text without really actively reading it. This covers things like TV subtitles and quick notes for myself, as well as things like advertising, calendars, branding, etc.
            % I have to train myself to notice language use
\note{}
}

\frame{\frametitle{Findings --- Linguistic 4}
        I read a very large number of very small texts
            % contrary to most corpora
\note{}
}

\frame{\frametitle{Findings --- Linguistic 5}
        Spoken language is *very* common and informal, compared to even the most informally-absorbed written texts
            % expected, really.
\note{}
}

\frame{\frametitle{Findings --- Linguistic 6}
    The vast majority of text I read is digital, but the vast majority of text sources I read are not.
\note{}
}



\frame{\frametitle{Findings --- Methodological}
    \begin{itemize}
        \item How often does one read a document when writing it?
        \item How deliberately must one read something like a brand for it to count?
        \item How to record doing multiple things?
        \item What of programming languages, music, numeric and symbolic information, maps, etc.?
    \end{itemize}
\note{}
}


\subsection*{Ethics}
\frame{\frametitle{Ethics}
Covert research is always ethically suspect, however:

    \begin{itemize}
        \item Data being captured is not sensitive
        \item There is no other way to capture small spoken utterances
        \item Little to no human listening ever occurs on the resultant data
        \item Automated obfuscation is possible if only taking word counts/proportions
            % such as garbling the speech without affecting frequencies, allowing VAD to still work
        \item Data may be optionally deleted after (nightly) notation in the log 
            % unless sampling verbatim recordings, any data sampled may be deleted after its main points have been
            % noted down.
    \end{itemize}
\note{
  BNC: announced their recordings and allowed for deletion on request
}
}


% TODO: summary, auxiliary slides

\section*{Summary}
\frame{\frametitle{Summary}
    \begin{itemize}
        \item One preliminary test complete; iteration of methods progressing
        \item Sampling methods have been refined, but show promise
        \item Annotation should be continuous (nightly) in order to reduce bulk of transcription effort
        \item Though a single-person sample is useful, multiple people could augment data using questionnaires and data mining
        
        \vspace{10pt}
        \item I welcome questions/feedback on methods for the next round of sampling!
    \end{itemize}
\note{}
}


\appendix

% Which variables are collected
\frame{\frametitle{Collected Variables}
    Variables for capture in daily log: 
    \begin{itemize}
        \item
    \end{itemize}
\note{}
}
\frame{\frametitle{Annotated Variables}
    Variables for annotation in final corpus
    \begin{itemize}
        \item
    \end{itemize}
\note{}
}

% -----------------------------------------------------------------------------------------
% 
% \frame{\frametitle{}
% \begin{columns} 
%     \begin{column}[c]{5cm} 
%     \end{column} 
%     \begin{column}[c]{5cm} 
%     \end{column} 
% \end{columns}
% 
% \note{}
% }
%
%
\frame{\frametitle{}
    \begin{itemize}
        \item
    \end{itemize}
\note{}
}
%
% \frame{\frametitle{}
% \note{}
% }
% -----------------------------------------------------------------------------------------
\end{document}
